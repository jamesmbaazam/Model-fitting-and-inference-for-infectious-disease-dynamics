<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>The particle MCMC</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
  <link rel="stylesheet" href="github-pandoc.css" type="text/css" />
</head>
<body>
<div id="header">
<h1 class="title">The particle MCMC</h1>
</div>
<div id="TOC">
<ul>
<li><a href="#objectives">Objectives</a></li>
<li><a href="#code-a-particle-filter">Code a particle filter</a></li>
<li><a href="#run-a-particle-filter">Run a particle filter</a></li>
<li><a href="#calibrate-the-number-of-particles">Calibrate the number of particles</a></li>
<li><a href="#run-a-pmcmc">Run a pMCMC</a></li>
<li><a href="#analyse-a-pmcmc-with-50-particles">Analyse a pMCMC with 50 particles</a></li>
<li><a href="#analyse-a-pmcmc-with-400-particles">Analyse a pMCMC with 400 particles</a></li>
<li><a href="#stochastic-vs-deterministic-fit">Stochastic vs deterministic fit</a></li>
<li><a href="#going-further">Going further</a></li>
</ul>
</div>
<h1 id="objectives">Objectives</h1>
<p>The aim of this session is to learn how you can fit a stochastic model using the particle MCMC Metropolis-Hastings algorithm (pMCMC). As you saw in the lecture, fitting a model with a likelihood approach requires:</p>
<ul>
<li>To explore the parameter space efficiently</li>
<li>To evaluate the likelihood at a given parameter</li>
</ul>
<p>In the <a href="play_with_seitl.html#fitting-the-deterministic-models">previous session</a>, you have used the function <code>mcmcMH</code> to explore the parameter space with a Metropolis-Hastings algorithm and the function <code>trajLogLike</code> to evaluate the likelihood for your deterministic model. In order to fit a stochastic model, we can still use the <code>mcmcMH</code> function to explore the parameter space efficiently but we need to use a new function to evaluate the likelihood. This new function is called a particle filter.</p>
<p>In this session you will:</p>
<ol style="list-style-type: decimal">
<li>code a particle filter to estimate the likelihood of a stochastic model</li>
<li>learn how to calibrate the number of particles</li>
<li>fit the stochastic SEIT2L model to the Tristan da Cunha outbreak with a pMCMC</li>
</ol>
<h1 id="code-a-particle-filter">Code a particle filter</h1>
<p>Before running a pMCMC, we need to code a particle filter in order to evaluate the log-likelihood of the data at a given proposed <code>theta</code>.</p>
<p>Below you can find the skeleton of such a function. We have inserted comments at each step of the algorithm. If you are struggling at any point, follow the link below the code for a more guided example.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># This is a function that takes four parameters:</span>
<span class="co"># - fitmodel: a fitmodel object</span>
<span class="co"># - theta: named numeric vector. Values of the parameters for which the marginal log-likelihood is desired.</span>
<span class="co"># - init.state: named numeric vector. Initial values of the state variables.</span>
<span class="co"># - data: data frame. Observation times and observed data.</span>
<span class="co"># The function returns the value of the marginal log-likelihood</span>
my_particleFilter &lt;-<span class="st"> </span>function(fitmodel, theta, init.state, data, n.particles) {

    ## Initialisation of the algorithm
    <span class="co"># Initialise the state and the weight of your particles</span>

    ## Start for() loop over observation times

        <span class="co"># Resample particles according to their weights</span>
        <span class="co"># You can use the `sample() function of R</span>

        ## Start for() loop over particles

            <span class="co"># Propagate the particle from current observation time to the next one</span>
            <span class="co"># using the function `fitmodel$simulate`</span>

            <span class="co"># Weight the particle with the likelihood of the observed data point</span>
            <span class="co"># using the function `fitmodel$pointLogLike`</span>

        ## End for() loop over particles

    ## End for() loop over observation times

    ## Compute and return the marginal log-likelihood
    <span class="co"># sum of the log of the mean of the weights at each observation time</span>

}</code></pre>
<p>If you have trouble filling any of the empty bits, have a look at our <a href="smc_example.html">more guided example</a>.</p>
<h1 id="run-a-particle-filter">Run a particle filter</h1>
<p>Try to run your particle filter with the following inputs:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load SEIT2L_sto</span>
<span class="kw">example</span>(SEIT2L_stochastic)

<span class="co"># load data</span>
<span class="kw">data</span>(FluTdC1971)

<span class="co"># theta close to the mean posterior estimate of the deterministic SEIT2L</span>
<span class="co"># model</span>
theta &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">R0 =</span> <span class="dv">7</span>, <span class="dt">D.lat =</span> <span class="dv">1</span>, <span class="dt">D.inf =</span> <span class="dv">4</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">D.imm =</span> <span class="dv">10</span>, <span class="dt">rho =</span> <span class="fl">0.65</span>)

<span class="co"># init state as before</span>
init.state &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">S =</span> <span class="dv">279</span>, <span class="dt">E =</span> <span class="dv">0</span>, <span class="dt">I =</span> <span class="dv">2</span>, <span class="dt">T1 =</span> <span class="dv">3</span>, <span class="dt">T2 =</span> <span class="dv">0</span>, <span class="dt">L =</span> <span class="dv">0</span>, <span class="dt">Inc =</span> <span class="dv">0</span>)

<span class="co"># run the particle filter with 20 particles</span>
<span class="kw">my_particleFilter</span>(SEIT2L_sto, theta, init.state, <span class="dt">data =</span> FluTdC1971, <span class="dt">n.particles =</span> <span class="dv">20</span>)
## [1] -125.8</code></pre>
<p>Does your particle filter return the same value for the marginal log-likelihood? Can you explain why?</p>
<p>What can you notice when you:</p>
<ul>
<li>Run several replicates with the same number of particles<br /></li>
<li>Increase the number of particles</li>
<li>Decrease the number of particles (try with one particle)</li>
<li>Change <code>theta</code></li>
</ul>
<h1 id="calibrate-the-number-of-particles">Calibrate the number of particles</h1>
<p>Can you think of and implement an algorithm to calibrate the number of particles?</p>
<p>Compare your approach with <a href="pmcmc_solution.html#calibrate-the-number-of-particles">ours</a> and determine an optimal number of particles.</p>
<h1 id="run-a-pmcmc">Run a pMCMC</h1>
<p>You can now write a new wrapper for the function <code>logPosterior</code> that will take <code>margLogLike = my_particleFilter</code> as argument. This wrapper will then be passed to <code>mcmcMH</code>.</p>
<p>Note that the function <code>logPosterior</code> doesn't take a 'n.particles' argument so you might wonder how to specify it to <code>my_particleFilter</code>? Have a look at the documentation of <code>logPosterior</code>. You should notice the <code>...</code> argument, which allows you to pass any extra argument to the function <code>margLogLike</code>.</p>
<p>You have probably noticed that running <code>my_particleFilter</code> is costly. As we mentioned in the <a href="play_with_seitl.html#fitting-the-deterministic-models">previous session</a> this can lead to a waste of time and computational resources if we initialise the <code>mcmcMH</code> with poor parameter values (<code>init.theta</code>) and covariance matrix of the Gaussian proposal (<code>covmat</code>).</p>
<p>In order to efficiently initialise your pMCMC, you can make use the results of the fit of the deterministic SEIT2L model of the previous session. Remember that you can load these results as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(mcmc_TdC_deter_longRun)
<span class="co"># this should load 2 objects in your environment:</span>
<span class="co"># mcmc_SEIT2L_infoPrior_theta1 and mcmc_SEIT2L_infoPrior_theta2. Each one is</span>
<span class="co"># a list of 3 elements returned by mcmcMH</span>
<span class="kw">names</span>(mcmc_SEIT2L_infoPrior_theta1)
## [1] &quot;trace&quot;            &quot;acceptance.rate&quot;  &quot;covmat.empirical&quot;</code></pre>
<p>You can now set the variables below:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># wrapper for posterior</span>
my_posteriorSto &lt;-<span class="st"> </span>function(theta){

    my_fitmodel &lt;-<span class="st"> </span><span class="co"># INSERT HERE</span>
<span class="st">    </span>my_init.state &lt;-<span class="st"> </span><span class="co"># INSERT HERE</span>
<span class="st">    </span>my_n.particles &lt;-<span class="st"> </span><span class="co"># INSERT HERE</span>

<span class="st">    </span><span class="kw">return</span>(<span class="kw">logPosterior</span>(<span class="dt">fitmodel=</span> my_fitmodel, <span class="dt">theta=</span>theta, <span class="dt">init.state=</span> my_init.state, 
        <span class="dt">data=</span>FluTdC1971, <span class="dt">margLogLike =</span> my_particleFilter, <span class="dt">n.particles=</span>my_n.particles))

}

<span class="co"># theta to initialise the pMCMC</span>
init.theta &lt;-<span class="st"> </span><span class="co"># INSERT HERE</span>

<span class="co"># covariance matrix for the Gaussian proposal</span>
covmat &lt;-<span class="st"> </span><span class="co"># INSERT HERE</span>

<span class="co"># lower and upper limits of each parameter (must be named vectors)</span>
lower &lt;-<span class="st"> </span><span class="co"># INSERT HERE</span>
upper &lt;-<span class="st"> </span><span class="co"># INSERT HERE</span>

<span class="co"># number of iterations for the pMCMC</span>
n.iterations &lt;-<span class="st"> </span><span class="co"># INSERT HERE</span>

<span class="co"># additional parameters for the adaptive pMCMC, see ?mcmcMH for more details</span>
adapt.size.start &lt;-<span class="st"> </span><span class="co"># INSERT HERE</span>
adapt.size.cooling &lt;-<span class="st"> </span><span class="co"># INSERT HERE</span>
adapt.shape.start &lt;-<span class="st"> </span><span class="co"># INSERT HERE</span></code></pre>
<p>If you have trouble filling some of the empty bits, have a look at our <a href="pmcmc_solution.html#setting-the-pmcmc">solution</a>.</p>
<p>Then you should be able to run <code>mcmcMH</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># run the pMCMC</span>
my_pMCMC &lt;-<span class="st"> </span><span class="kw">mcmcMH</span>(<span class="dt">target =</span> my_posteriorSto, <span class="dt">init.theta =</span> init.theta, <span class="dt">covmat =</span> covmat, 
    <span class="dt">limits =</span> <span class="kw">list</span>(<span class="dt">lower =</span> lower, <span class="dt">upper =</span> upper), <span class="dt">n.iterations =</span> n.iterations, 
    <span class="dt">adapt.size.start =</span> adapt.size.start, <span class="dt">adapt.size.cooling =</span> adapt.size.cooling, 
    <span class="dt">adapt.shape.start =</span> adapt.shape.start)</code></pre>
<h1 id="analyse-a-pmcmc-with-50-particles">Analyse a pMCMC with 50 particles</h1>
<p>If you have run a pMCMC you should have noticed that it takes quite a lot of time due to the particle filter at each iterations. Since the computation time scales linearly with the number of particles you might be tempted to reduce this number. Let's have a look at what we would get by running a pMCMC with 50 particles.</p>
<p>To save time, we have run 5 chains in parallel. Each chain was started from a different <code>init.theta</code> and run for 3000 iterations. The <code>init.theta</code> were chosen close to the mean posterior estimates of the deterministic fit and it's empirical covariance matrix was also used for the Gaussian proposal kernel. Each chain took 6 hours to complete on a scientific cluster and can be loaded as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(pmcmc_SEIT2L_infoPrior_n50)
<span class="co"># this should load a list with the same name, which contains the 5 chains.</span>
<span class="kw">names</span>(pmcmc_SEIT2L_infoPrior_n50)
## [1] &quot;chain1&quot; &quot;chain2&quot; &quot;chain3&quot; &quot;chain4&quot; &quot;chain5&quot;
<span class="co"># each chain is a list of 3 elements returned by mcmcMH</span>
<span class="kw">names</span>(pmcmc_SEIT2L_infoPrior_n50[[<span class="st">&quot;chain1&quot;</span>]])
## [1] &quot;trace&quot;            &quot;acceptance.rate&quot;  &quot;covmat.empirical&quot;
<span class="co"># the trace contains 9 variables for 3000 iterations</span>
<span class="kw">dim</span>(pmcmc_SEIT2L_infoPrior_n50[[<span class="st">&quot;chain1&quot;</span>]]$trace)
## [1] 3001    9</code></pre>
<p>We can combine the traces of the 5 chains into a <code>mcmc.list</code> object as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r">trace &lt;-<span class="st"> </span><span class="kw">mcmc.list</span>(<span class="kw">lapply</span>(pmcmc_SEIT2L_infoPrior_n50, function(chain) {
    <span class="kw">mcmc</span>(chain$trace)
}))
<span class="kw">head</span>(trace, <span class="dv">1</span>)
## $chain1
## Markov Chain Monte Carlo (MCMC) output:
## Start = 1 
## End = 2 
## Thinning interval = 1 
##      R0 D.lat D.inf  alpha D.imm    rho log.prior log.likelihood
## 1 6.485 1.334 2.918 0.4858 9.985 0.6732    -10.24         -123.5
## 2 6.485 1.334 2.918 0.4858 9.985 0.6732    -10.24         -123.5
##   log.posterior
## 1        -133.7
## 2        -133.7
## 
## $chain2
## Markov Chain Monte Carlo (MCMC) output:
## Start = 1 
## End = 2 
## Thinning interval = 1 
##      R0 D.lat D.inf  alpha D.imm    rho log.prior log.likelihood
## 1 6.375 1.307 2.856 0.4915 9.853 0.6658   -10.202         -121.7
## 2 5.776 1.436 1.986 0.4594 7.243 0.6761    -9.755         -121.7
##   log.posterior
## 1        -131.9
## 2        -131.5
## 
## $chain3
## Markov Chain Monte Carlo (MCMC) output:
## Start = 1 
## End = 2 
## Thinning interval = 1 
##      R0 D.lat D.inf  alpha D.imm    rho log.prior log.likelihood
## 1 6.335 1.275 2.885 0.4913 9.977 0.6759    -10.25         -121.9
## 2 7.276 1.206 3.332 0.5210 8.220 0.6409    -10.80         -119.2
##   log.posterior
## 1        -132.2
## 2        -130.0
## 
## $chain4
## Markov Chain Monte Carlo (MCMC) output:
## Start = 1 
## End = 2 
## Thinning interval = 1 
##      R0 D.lat D.inf  alpha D.imm    rho log.prior log.likelihood
## 1 6.198 1.303 2.863 0.4915 9.812 0.6653    -10.21         -121.8
## 2 6.198 1.303 2.863 0.4915 9.812 0.6653    -10.21         -121.8
##   log.posterior
## 1          -132
## 2          -132
## 
## $chain5
## Markov Chain Monte Carlo (MCMC) output:
## Start = 1 
## End = 2 
## Thinning interval = 1 
##      R0 D.lat D.inf  alpha D.imm    rho log.prior log.likelihood
## 1 5.432 1.211 2.515 0.4851 9.826 0.6776    -10.04         -121.2
## 2 5.432 1.211 2.515 0.4851 9.826 0.6776    -10.04         -121.2
##   log.posterior
## 1        -131.2
## 2        -131.2
## 
## attr(,&quot;class&quot;)
## [1] &quot;mcmc.list&quot;</code></pre>
<p>You can check that the chains were started from different <code>init.state</code> and that we used informative priors.</p>
<p><strong>Take 15 min</strong> to analyse these chains and conclude on the choice of using 50 particles to save computation time.</p>
<p>You can compare your conclusions with <a href="pmcmc_solution.html#analyse-a-pmcmc-with-50-particles">ours</a>.</p>
<h1 id="analyse-a-pmcmc-with-400-particles">Analyse a pMCMC with 400 particles</h1>
<p>Let's increase the number of particles to 400, which is suggested by the calibration analysis. Again, to save time we have run 5 chains of 3000 iterations in parallel. Each chain took 40 hours to complete on a scientific cluster and can be loaded and stored in a <code>mcmc.list</code> object as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load</span>
<span class="kw">data</span>(pmcmc_SEIT2L_infoPrior_n400)
<span class="co"># create</span>
trace &lt;-<span class="st"> </span><span class="kw">mcmc.list</span>(<span class="kw">lapply</span>(pmcmc_SEIT2L_infoPrior_n50, function(chain) {
    <span class="kw">mcmc</span>(chain$trace)
}))</code></pre>
<p>Re-do the same analysis as for 50 particles. What differences can you notice? In particular, try to compare the posterior distributions of both sets of runs using the function <code>plotPosteriorDensity</code>.</p>
<p>Have a look at our <a href="pmcmc_solution.html#analyse-a-pmcmc-with-400-particles">solution</a>.</p>
<h1 id="stochastic-vs-deterministic-fit">Stochastic vs deterministic fit</h1>
<p>Finally, compare the posterior of the deterministic and stochastic SEIT2L models. Was it worth fitting a stochastic model to this outbreak?</p>
<p>Have a look at our <a href="pmcmc_solution.html#stochastic-vs-deterministic-fit">solution</a>.</p>
<h1 id="going-further">Going further</h1>
<ul>
<li><p>Actually, in addition to the log-likelihood, a particle filter can also return the filtered trajectories (i.e. all the trajectories that &quot;survived&quot; until the last observation time). You can update your filter so it keeps track and returns these filtered trajectories. Alternatively, there is a function in the package that will do it for you (see <code>?bootstrapParticleFilter</code>).</p></li>
<li><p>You might have noted that the <code>for()</code> loop over particles could be parallelized, as particles can be propagated independently. You could take advantage of this to code a parallel loop and make your algorithm even faster. If you have never coded a parallel program in R you can also have a look at the code of <code>bootstrapParticleFilter</code>. Actually, all the test run were performed on a scientific cluster with 12 core machines. So the computational time is expected to be multiplied by 12 without parallelization of the particle filter.</p></li>
</ul>
<div>
<h1>Navigate</h1>
Previous: <a href="play_with_seitl.html">Tristan da Cunha outbreak</a> Next: <a href="ABC.html">Inference with ABC</a>
</div>
</body>
</html>
